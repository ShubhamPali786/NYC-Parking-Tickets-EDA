{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating Spark Session Driver Program\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(name= \"NycTicket_App\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Summons Number: long (nullable = true)\n",
      " |-- Plate ID: string (nullable = true)\n",
      " |-- Registration State: string (nullable = true)\n",
      " |-- Issue Date: timestamp (nullable = true)\n",
      " |-- Violation Code: integer (nullable = true)\n",
      " |-- Vehicle Body Type: string (nullable = true)\n",
      " |-- Vehicle Make: string (nullable = true)\n",
      " |-- Violation Precinct: integer (nullable = true)\n",
      " |-- Issuer Precinct: integer (nullable = true)\n",
      " |-- Violation Time: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading Data in dataframe\n",
    "df = spark.read.format(\"csv\").option(\n",
    "                \"inferSchema\",\"True\").option(\n",
    "                \"header\",\"True\").load(\"/common_folder/nyc_parking/Parking_Violations_Issued_-_Fiscal_Year_2017.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter dataframe to get only 2017 finacial year data as described in Problem statement\n",
    "from pyspark.sql.functions import year\n",
    "\n",
    "df = df.filter(year(\"Issue Date\") == 2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|Summons Number|Plate ID|Registration State|Issue Date|Violation Code|Vehicle Body Type|Vehicle Make|Violation Precinct|Issuer Precinct|Violation Time|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "|             0|       0|                 0|         0|             0|                0|           0|                 0|              0|             0|\n",
      "+--------------+--------+------------------+----------+--------------+-----------------+------------+------------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count null columns\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see there's no null value across all columns, we can proceed with Data Analysis now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT Summons Number)|\n",
      "+------------------------------+\n",
      "|                       5431918|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.\tFind the total number of tickets for the year.\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.agg(countDistinct(\"Summons Number\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------+\n",
      "|Registration State|Total_Tickets_Frequency|\n",
      "+------------------+-----------------------+\n",
      "|                NY|                4273951|\n",
      "|                NJ|                 475825|\n",
      "|                PA|                 140286|\n",
      "|                CT|                  70403|\n",
      "|                FL|                  69468|\n",
      "+------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.\tFind out the number of unique states from where the cars that got parking tickets came.\n",
    "from pyspark.sql.functions import desc,col\n",
    "df.groupBy(\"Registration State\").agg(\n",
    "   count(\"Registration State\").alias(\"Total_Tickets_Frequency\")\n",
    "    ).sort(desc(\"Total_Tickets_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There is a numeric entry '99' in the column, which should be corrected. Replace it with the state having the maximum entries.\n",
    "# it is NY in our case.\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\"Registration State\",when(df[\"Registration State\"] == \"99\",\"NY\").otherwise(df[\"Registration State\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------+\n",
      "|Registration State|Total_Tickets_Frequency|\n",
      "+------------------+-----------------------+\n",
      "|                NY|                4290006|\n",
      "|                NJ|                 475825|\n",
      "|                PA|                 140286|\n",
      "|                CT|                  70403|\n",
      "|                FL|                  69468|\n",
      "+------------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Recalculate number of unique states from where the cars that got parking tickets came.\n",
    "df.groupBy(\"Registration State\").agg(\n",
    "   count(\"Registration State\").alias(\"Total_Tickets_Frequency\")\n",
    "    ).sort(desc(\"Total_Tickets_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tHow often does each violation code occur? Display the frequency of the top five violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|Violation Code|ViolationCode_Frequency|\n",
      "+--------------+-----------------------+\n",
      "|            21|                 768087|\n",
      "|            36|                 662765|\n",
      "|            38|                 542079|\n",
      "|            14|                 476664|\n",
      "|            20|                 319646|\n",
      "+--------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Violation Code\").agg(\n",
    "    count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "    ).sort(desc(\"ViolationCode_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tHow often does each 'vehicle body type' get a parking ticket? How about the 'vehicle make'? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------+\n",
      "|Vehicle Body Type|VehicleBody_Frequency|\n",
      "+-----------------+---------------------+\n",
      "|             SUBN|              1883954|\n",
      "|             4DSD|              1547312|\n",
      "|              VAN|               724029|\n",
      "|             DELV|               358984|\n",
      "|              SDN|               194197|\n",
      "+-----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------------+---------------------+\n",
      "|Vehicle Make|VehicleMake_Frequency|\n",
      "+------------+---------------------+\n",
      "|        FORD|               636844|\n",
      "|       TOYOT|               605291|\n",
      "|       HONDA|               538884|\n",
      "|       NISSA|               462017|\n",
      "|       CHEVR|               356032|\n",
      "+------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.\tHow often does each 'vehicle body type' get a parking ticket?\n",
    "#(Hint: Find the top 5 for both.)\n",
    "df.groupBy(\"Vehicle Body Type\").agg(\n",
    "    count(\"Vehicle Body Type\").alias(\"VehicleBody_Frequency\")\n",
    "    ).sort(desc(\"VehicleBody_Frequency\")).show(5)\n",
    "\n",
    "#How about the 'vehicle make'? \n",
    "df.groupBy(\"Vehicle Make\").agg(\n",
    "    count(\"Vehicle Make\").alias(\"VehicleMake_Frequency\")\n",
    "    ).sort(desc(\"VehicleMake_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tA precinct is a police station that has a certain zone of the city under its command. Find the (5 highest) frequencies of tickets for each of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i)'Violation Precinct' (This is the precinct of the zone where the violation occurred).Using this, can you draw any insights for parking violations in any specific area of the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+\n",
      "|Violation Precinct|Registration State|Violation_Frequency|\n",
      "+------------------+------------------+-------------------+\n",
      "|                19|                NY|             211375|\n",
      "|                14|                NY|             133169|\n",
      "|               114|                NY|             122394|\n",
      "|                 1|                NY|             120535|\n",
      "|                18|                NY|             110121|\n",
      "+------------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1.\t'Violation Precinct' (This is the precinct of the zone where the violation occurred).\n",
    "# Using this, can you draw any insights for parking violations in any specific area of the city?\n",
    "df.filter(col(\"Issuer Precinct\") != 0\n",
    "        ).groupBy(\"Violation Precinct\",\"Registration State\").agg(\n",
    "        count(\"Violation Precinct\").alias(\"Violation_Frequency\")\n",
    "        ).sort(desc(\"Violation_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Violation Frequencies are high in 19 Precinct Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii)'Issuer Precinct' (This is the precinct that issued the ticket.)\n",
    "Here, you would have noticed that the dataframe has the'Violating Precinct' or 'Issuing Precinct' as '0'.\n",
    "These are erroneous entries. Hence, you need to provide records for five correct precincts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+-------------------+\n",
      "|Issuer Precinct|Registration State|Violation_Frequency|\n",
      "+---------------+------------------+-------------------+\n",
      "|             19|                NY|             206463|\n",
      "|             14|                NY|             131462|\n",
      "|            114|                NY|             121652|\n",
      "|              1|                NY|             120077|\n",
      "|             18|                NY|             106446|\n",
      "+---------------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.\t'Issuer Precinct' (This is the precinct that issued the ticket.)\n",
    "#Here, you would have noticed that the dataframe has the'Violating Precinct' or 'Issuing Precinct' as '0'.\n",
    "#These are erroneous entries. Hence, you need to provide records for five correct precincts.\n",
    "\n",
    "df.filter(col(\"Issuer Precinct\") != 0\n",
    "         ).groupBy(\"Issuer Precinct\",\"Registration State\").agg(\n",
    "        count(\"Issuer Precinct\").alias(\"Violation_Frequency\")\n",
    "        ).sort(desc(\"Violation_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tFind the violation code frequency for three precincts that have issued the most number of tickets. Do these precinct zones have an exceptionally high frequency of certain violation codes? Are these codes common across precincts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|Violation Code|ViolationCode_Frequency|\n",
      "+--------------+-----------------------+\n",
      "|            46|                  50785|\n",
      "|            38|                  37483|\n",
      "|            37|                  36468|\n",
      "|            14|                  30376|\n",
      "|            21|                  29415|\n",
      "+--------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+-----------------------+\n",
      "|Violation Code|ViolationCode_Frequency|\n",
      "+--------------+-----------------------+\n",
      "|            14|                  45885|\n",
      "|            69|                  30465|\n",
      "|            31|                  22649|\n",
      "|            47|                  18691|\n",
      "|            42|                  10027|\n",
      "+--------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+-----------------------+\n",
      "|Violation Code|ViolationCode_Frequency|\n",
      "+--------------+-----------------------+\n",
      "|            21|                  35317|\n",
      "|            38|                  27123|\n",
      "|            37|                  18636|\n",
      "|            20|                  12785|\n",
      "|            71|                   9785|\n",
      "+--------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Violation Precinct\") ==19 ).groupBy(\"Violation Code\").agg(\n",
    "    count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "    ).sort(desc(\"ViolationCode_Frequency\")).show(5)\n",
    "\n",
    "df.filter(col(\"Violation Precinct\") ==14 ).groupBy(\"Violation Code\").agg(\n",
    "    count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "    ).sort(desc(\"ViolationCode_Frequency\")).show(5)\n",
    "\n",
    "df.filter(col(\"Violation Precinct\") ==114 ).groupBy(\"Violation Code\").agg(\n",
    "    count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "    ).sort(desc(\"ViolationCode_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+-----------------------+\n",
      "|Violation Code|Violation Precinct|violationCode_Frequency|\n",
      "+--------------+------------------+-----------------------+\n",
      "|            46|                19|                  50785|\n",
      "|            14|                14|                  45885|\n",
      "|            38|                19|                  37483|\n",
      "|            37|                19|                  36468|\n",
      "|            21|               114|                  35317|\n",
      "|            69|                14|                  30465|\n",
      "|            14|                19|                  30376|\n",
      "|            21|                19|                  29415|\n",
      "|            38|               114|                  27123|\n",
      "|            31|                14|                  22649|\n",
      "|            47|                14|                  18691|\n",
      "|            37|               114|                  18636|\n",
      "|            20|                19|                  15132|\n",
      "|            20|               114|                  12785|\n",
      "|            40|                19|                  11519|\n",
      "|            42|                14|                  10027|\n",
      "|            16|                19|                  10006|\n",
      "|            71|               114|                   9785|\n",
      "|            46|                14|                   8411|\n",
      "|            40|               114|                   7805|\n",
      "|            71|                19|                   7567|\n",
      "|            19|                14|                   7455|\n",
      "|            19|                19|                   7066|\n",
      "|            84|                14|                   6749|\n",
      "|            70|               114|                   6173|\n",
      "|            14|               114|                   5717|\n",
      "|            10|                19|                   5669|\n",
      "|            82|                14|                   5052|\n",
      "|            84|                19|                   4928|\n",
      "|            70|                19|                   4503|\n",
      "+--------------+------------------+-----------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Py SQL Method :\n",
    "df.registerTempTable(\"violation_frequency_table\")\n",
    "temp_table = spark.sql(\n",
    "    \"select `Violation Code`,`Violation Precinct`, count(`Violation Code`) as violationCode_Frequency\" \n",
    "    +\" from violation_frequency_table GROUP BY  `Violation Code`, `Violation Precinct` order by violationCode_Frequency desc\"\n",
    ")\n",
    "temp_table.where('`Violation Precinct`= 19 or `Violation Precinct`= 14 or `Violation Precinct`= 114').show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precinct zones 19 & 14 have extreamly high frequencies for violation code 46 & 14. Violation Code 14 is common across precincts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tFind out the properties of parking violations across different times of the day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i)\tFind a way to deal with missing values, if any.\n",
    "(Hint: Check for the null values using 'isNull' under the SQL. Also, to remove the null values, check the 'dropna' command in the API documentation.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431918"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop records with null value\n",
    "df = df.na.drop()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii)\tThe Violation Time field is specified in a strange format. Find a way to make this a time attribute that you can use to divide into groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable(\"violation_Time_tbl\")\n",
    "\n",
    "formatted_timeTBL= spark.sql(\"Select `Violation Code`, Case\"\n",
    "+\" When `Violation Time` like '%A' THEN\" \n",
    "+\" to_timestamp(REPLACE(CONCAT(SUBSTRING(`Violation Time`,1,2),':',SUBSTRING(`Violation Time`,3)),'A',' AM'),'h:mm a')\"\n",
    "+\" When `Violation Time` like '%P' THEN\"\n",
    "+\" to_timestamp(REPLACE(CONCAT(SUBSTRING(`Violation Time`,1,2),':',SUBSTRING(`Violation Time`,3)),'P',' PM'),'h:mm a')\"\n",
    "+\" END AS formatted_Time FROM violation_Time_tbl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|Violation Code|     formatted_Time|\n",
      "+--------------+-------------------+\n",
      "|            47|1970-01-01 11:20:00|\n",
      "|             7|1970-01-01 20:52:00|\n",
      "|            40|1970-01-01 05:25:00|\n",
      "+--------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning to have only 24 hrs time\n",
    "from pyspark.sql.functions import hour, col\n",
    "formatted_timeTBL = formatted_timeTBL.filter(hour(\"formatted_Time\")<24)\n",
    "formatted_timeTBL.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Divide 24 hours into six equal discrete bins of time. Choose the intervals as you see fit. For each of these groups, find the three most commonly occurring violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formatted_timeTBL.registerTempTable(\"bucketing_table\")\n",
    "\n",
    "bucketing_table =  spark.sql(\"SELECT `Violation Code`, CASE\"\n",
    "     +\" WHEN EXTRACT(HOUR FROM formatted_Time) BETWEEN 0 AND 6 THEN '0-6'\"\n",
    "     +\" WHEN EXTRACT(HOUR FROM formatted_Time) BETWEEN 7 AND 12 THEN '7-12'\"\n",
    "     +\" WHEN EXTRACT(HOUR FROM formatted_Time) BETWEEN 13 AND 18 THEN '13-18'\"\n",
    "     +\" WHEN EXTRACT(HOUR FROM formatted_Time) BETWEEN 19 AND 24 THEN '19-24'\"\n",
    "     +\" END AS time_Interval from bucketing_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+-----------------------+\n",
      "|Violation Code|time_Interval|ViolationCode_Frequency|\n",
      "+--------------+-------------+-----------------------+\n",
      "|            21|         7-12|                 723254|\n",
      "|            36|         7-12|                 464933|\n",
      "|            38|        13-18|                 286253|\n",
      "|            38|         7-12|                 233585|\n",
      "|            14|         7-12|                 227728|\n",
      "+--------------+-------------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, desc\n",
    "bucketing_table.groupBy(\"time_Interval\",\"Violation Code\").agg(\n",
    "                count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "                ).select(col(\"Violation Code\"), col(\"time_Interval\"),\n",
    "                 col(\"ViolationCode_Frequency\")\n",
    "                ).sort(desc(\"ViolationCode_Frequency\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii) Now, try another direction. For the three most commonly occurring violation codes, find the most common time of the day (in terms of the bins from the previous part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+----------------------+\n",
      "|Violation Code|time_Interval|timeInterval_Frequency|\n",
      "+--------------+-------------+----------------------+\n",
      "|            38|         7-12|                233585|\n",
      "|            36|         7-12|                464933|\n",
      "|            21|         7-12|                723254|\n",
      "+--------------+-------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucketing_table.registerTempTable(\"commontime_table\")\n",
    "commontime_table = spark.sql(\n",
    "    \"select `Violation Code`,time_Interval, count(time_Interval) as timeInterval_Frequency\" \n",
    "    +\" from commontime_table GROUP BY  time_Interval, `Violation Code` order by time_Interval desc\"\n",
    ")\n",
    "commontime_table.where('`Violation Code`= 21 or `Violation Code`= 36 or `Violation Code`= 38').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tLet’s try and find some seasonality in this data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i)\tFirst, divide the year into a certain number of seasons, and find frequencies of tickets for each season. (Hint: Use Issue Date to segregate into seasons.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+\n",
      "|Season|ticket_frequency|\n",
      "+------+----------------+\n",
      "|SPRING|         2873383|\n",
      "|WINTER|         1705669|\n",
      "|SUMMER|          852866|\n",
      "+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable('seasonality_table')\n",
    "\n",
    "spark.sql(\"SELECT CASE\"\n",
    "    +\" WHEN MONTH(`Issue Date`) in (3,4,5) THEN 'SPRING'\"\n",
    "    +\" WHEN MONTH(`Issue Date`) in (6,7,8) THEN 'SUMMER'\"\n",
    "    +\" ELSE 'WINTER'\"\n",
    "    +\" END AS Season , COUNT(DISTINCT `Summons Number`) AS ticket_frequency\"      \n",
    "    +\" FROM seasonality_table GROUP BY Season ORDER BY ticket_frequency DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) Find the three most common violations for each of these seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-------------------+\n",
      "|Season|Violation Code|violation_frequency|\n",
      "+------+--------------+-------------------+\n",
      "|SPRING|            21|             402424|\n",
      "|SPRING|            36|             344834|\n",
      "|SPRING|            38|             271167|\n",
      "|SPRING|            14|             256397|\n",
      "|WINTER|            21|             238311|\n",
      "|WINTER|            36|             221268|\n",
      "|WINTER|            38|             187394|\n",
      "|SPRING|            46|             173440|\n",
      "|SPRING|            20|             157122|\n",
      "|SPRING|            37|             151049|\n",
      "|SPRING|            40|             147408|\n",
      "|WINTER|            14|             142356|\n",
      "|SPRING|            71|             135351|\n",
      "|SUMMER|            21|             127352|\n",
      "|SPRING|             7|             122644|\n",
      "|WINTER|            20|              98050|\n",
      "|WINTER|            37|              97814|\n",
      "|SUMMER|            36|              96663|\n",
      "|WINTER|            46|              96222|\n",
      "|WINTER|            40|              86920|\n",
      "+------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT CASE\"\n",
    "    +\" WHEN MONTH(`Issue Date`) in (3,4,5) THEN 'SPRING'\"\n",
    "    +\" WHEN MONTH(`Issue Date`) in (6,7,8) THEN 'SUMMER'\"\n",
    "    +\" ELSE 'WINTER'\"\n",
    "    +\" END AS Season ,`Violation Code`, COUNT(`Violation Code`) AS violation_frequency\"      \n",
    "    +\" FROM seasonality_table GROUP BY Season,`Violation Code` ORDER BY violation_frequency DESC\"\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common violation code is 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. The fines collected from all instances of parking violation constitute a source of revenue for the NYC Police Department. Let’s take an example of estimating that for the three most commonly occurring codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Find the total occurrences of the three most common violation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------+\n",
      "|Violation Code|ViolationCode_Frequency|\n",
      "+--------------+-----------------------+\n",
      "|            21|                 768087|\n",
      "|            36|                 662765|\n",
      "|            38|                 542079|\n",
      "+--------------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Violation Code\").agg(\n",
    "    count(\"Violation Code\").alias(\"ViolationCode_Frequency\")\n",
    "    ).sort(desc(\"ViolationCode_Frequency\")).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 visit the website:\n",
    "http://www1.nyc.gov/site/finance/vehicles/services-violation-codes.page\n",
    "It lists the fines associated with different violation codes. They’re divided into two categories: one for the highest-density locations in the city and the other for the rest of the city. For the sake of simplicity, take the average of the two.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Using this information, find the total amount collected for the three violation codes with the maximum tickets. State the code that has the highest total collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-----------------------+--------------------+\n",
      "|Violation Code|ViolationAmount|ViolationCode_Frequency|TotalAmountCollected|\n",
      "+--------------+---------------+-----------------------+--------------------+\n",
      "|            21|           86.5|                 768087|          66439525.5|\n",
      "|            36|           50.0|                 662765|          33138250.0|\n",
      "|            38|           82.5|                 542079|          44721517.5|\n",
      "+--------------+---------------+-----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.registerTempTable('total_Collection_table')\n",
    "\n",
    "total_amountTBL=spark.sql(\"SELECT `Violation Code`,CASE\"\n",
    "    +\" WHEN  `Violation Code` = 21 THEN 86.5\"\n",
    "    +\" WHEN  `Violation Code` = 36 THEN 50\"\n",
    "    +\" WHEN  `Violation Code` = 38 THEN 82.5\"\n",
    "    +\" END AS ViolationAmount, COUNT(`Violation Code`) as ViolationCode_Frequency\"\n",
    "    +\" FROM total_Collection_table\"\n",
    "    +\" GROUP BY `Violation Code` ORDER BY ViolationCode_Frequency DESC LIMIT 3\"\n",
    ")\n",
    "\n",
    "total_amountTBL.select(\n",
    "    \"Violation Code\",\"ViolationAmount\",\"ViolationCode_Frequency\",\n",
    "    (col(\"ViolationAmount\") * col(\"ViolationCode_Frequency\")).alias(\"TotalAmountCollected\")\n",
    "    ).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violation Code 21 has maximum collection of 66439525.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
